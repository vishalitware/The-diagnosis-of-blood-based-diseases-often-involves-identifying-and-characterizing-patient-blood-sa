{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dataset with batch size of 32...\n",
      "Found 12515 images belonging to 1 classes.\n",
      "Found 366 images belonging to 2 classes.\n",
      "Dataset loaded\n",
      "Building model...\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 278s 3us/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'merge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-9cef151502f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;31m# Merging both cnn bottleneck and rnn's output wise element wise multiplication\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcnn_bottleneck\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnn_output\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mul'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'merge' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.applications.xception import Xception\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.engine import Input, merge\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Reshape, Lambda, K, LSTM\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "\n",
    "class CustomImageDataGenerator(ImageDataGenerator):\n",
    "    \"\"\"\n",
    "    Because Xception utilizes a custom preprocessing method, the only way to utilize this\n",
    "    preprocessing method using the ImageDataGenerator is to overload the standardize method.\n",
    "    The standardize method gets applied to each batch before ImageDataGenerator yields that batch.\n",
    "    \"\"\"\n",
    "\n",
    "    def standardize(self, x):\n",
    "        \"\"\"\n",
    "        Taken from keras.applications.xception.preprocess_input\n",
    "        \"\"\"\n",
    "        if self.featurewise_center:\n",
    "            x /= 255.\n",
    "            x -= 0.5\n",
    "            x *= 2.\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_training_generator(batch_size=128):\n",
    "    train_data_dir = 'D:/blood-cells/dataset2-master'\n",
    "    validation_data_dir = 'D:/blood-cells/dataset-master'\n",
    "    image_datagen = CustomImageDataGenerator(featurewise_center=True)\n",
    "\n",
    "    train_generator = image_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    val_generator = image_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_generator, val_generator\n",
    "\n",
    "\n",
    "def rgb_to_grayscale(input):\n",
    "    \"\"\"Average out each pixel across its 3 RGB layers resulting in a grayscale image\"\"\"\n",
    "    return K.mean(input, axis=3)\n",
    "\n",
    "\n",
    "def rgb_to_grayscale_output_shape(input_shape):\n",
    "    return input_shape[:-1]\n",
    "\n",
    "\n",
    "batch_size_phase_one = 32\n",
    "batch_size_phase_two = 16\n",
    "nb_val_samples = 5000\n",
    "\n",
    "nb_epochs = 30\n",
    "\n",
    "img_width = 299\n",
    "img_height = 299\n",
    "\n",
    "# Setting tensorbord callback\n",
    "now = time.strftime(\"%c\")\n",
    "tensorboard_callback = TensorBoard(log_dir='./logs/' + 'cnn_rnn ' + now, histogram_freq=0, write_graph=True,\n",
    "                                   write_images=False)\n",
    "\n",
    "# Loading dataset\n",
    "print(\"Loading the dataset with batch size of {}...\".format(batch_size_phase_one))\n",
    "train_generator, val_generator = get_training_generator(batch_size_phase_one)\n",
    "print(\"Dataset loaded\")\n",
    "\n",
    "print(\"Building model...\")\n",
    "input_tensor = Input(shape=(img_width, img_height, 3))\n",
    "\n",
    "# Creating CNN\n",
    "cnn_model = Xception(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "\n",
    "x = cnn_model.output\n",
    "cnn_bottleneck = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Make CNN layers not trainable\n",
    "for layer in cnn_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Creating RNN\n",
    "x = Lambda(rgb_to_grayscale, rgb_to_grayscale_output_shape)(input_tensor)\n",
    "x = Reshape((23, 3887))(x)  # 23 timesteps, input dim of each timestep 3887\n",
    "x = LSTM(2048, return_sequences=True)(x)\n",
    "rnn_output = LSTM(2048)(x)\n",
    "\n",
    "# Merging both cnn bottleneck and rnn's output wise element wise multiplication\n",
    "x = merge([cnn_bottleneck, rnn_output], mode='mul')\n",
    "predictions = Dense(100, activation='softmax')(x)\n",
    "\n",
    "model = Model(input=input_tensor, output=predictions)\n",
    "\n",
    "print(\"Model built\")\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "print(\"Starting training\")\n",
    "checkpointer = ModelCheckpoint(filepath=\"./initial_cnn_rnn_weights_2.hdf5\", verbose=1, save_best_only=True)\n",
    "model.fit_generator(train_generator, samples_per_epoch=4480, nb_epoch=nb_epochs, verbose=1,\n",
    "                    validation_data=val_generator,\n",
    "                    nb_val_samples=nb_val_samples,\n",
    "                    callbacks=[tensorboard_callback, checkpointer])\n",
    "\n",
    "print(\"Initial training done, starting phase two (finetuning)\")\n",
    "\n",
    "# Load two new generator with smaller batch size, needed because using the same batch size\n",
    "# for the fine tuning will result in GPU running out of memory and tensorflow raising an error\n",
    "print(\"Loading the dataset with batch size of {}...\".format(batch_size_phase_two))\n",
    "train_generator, val_generator = get_training_generator(batch_size_phase_two)\n",
    "print(\"Dataset loaded\")\n",
    "\n",
    "# Load best weights from initial training\n",
    "model.load_weights(\"./initial_cnn_rnn_weights_2.hdf5\")\n",
    "\n",
    "# Make all layers trainable for finetuning\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', 'top_k_categorical_accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"./finetuned_cnn_rnn_weights_2.hdf5\", verbose=1, save_best_only=True,\n",
    "                               monitor='val_acc')\n",
    "model.fit_generator(train_generator, samples_per_epoch=2240, nb_epoch=nb_epochs, verbose=1,\n",
    "                    validation_data=val_generator,\n",
    "                    nb_val_samples=nb_val_samples,\n",
    "                    callbacks=[tensorboard_callback, checkpointer])\n",
    "\n",
    "# Final evaluation of the model\n",
    "print(\"Training done, doing final evaluation...\")\n",
    "\n",
    "model.load_weights(\"./finetuned_cnn_rnn_weights_2.hdf5\")\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', 'top_k_categorical_accuracy'])\n",
    "\n",
    "scores = model.evaluate_generator(val_generator, val_samples=nb_val_samples)\n",
    "print(model.metrics_names, scores)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
